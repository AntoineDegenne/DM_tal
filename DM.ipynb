{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de documents : prise en main des outils\n",
    "\n",
    "Le but de ce TP est de classer des documents textuels... Dans un premier temps, nous allons vérifier le bon fonctionnement des outils sur des données jouets puis appliquer les concepts sur des données réelles.\n",
    "\n",
    "\n",
    "## Conception de la chaine de traitement\n",
    "Pour rappel, une chaine de traitement de documents classique est composée des étapes suivantes:\n",
    "1. Lecture des données et importation\n",
    "    - Dans le cadre de nos TP, nous faisons l'hypothèse que le corpus tient en mémoire... Si ce n'est pas le cas, il faut alors ajouter des structures de données avec des buffers (*data-reader*), bien plus complexes à mettre en place.\n",
    "    - Le plus grand piège concerne l'encodage des données. Dans le TP... Pas (ou peu) de problème. Dans la vraie vie: il faut faire attention à toujours maitriser les formats d'entrée et de sortie.\n",
    "1. Traitement des données brutes paramétrique. Chaque traitement doit être activable ou desactivable + paramétrable si besoin.\n",
    "    - Enlever les informations *inutiles* : chiffre, ponctuations, majuscules, etc... <BR>\n",
    "    **L'utilité dépend de l'application!**\n",
    "    - Segmenter en mots (=*Tokenization*)\n",
    "    - Elimination des stop-words\n",
    "    - Stemming/lemmatisation (racinisation)\n",
    "    - Byte-pair encoding pour trouver les mots composés (e.g. Sorbonne Université, Ville de Paris, Premier Ministre, etc...)\n",
    "1. Traitement des données numériques\n",
    "    - Normalisation *term-frequency* / binarisation\n",
    "    - Normalisation *inverse document frequency*\n",
    "    - Elimination des mots rares, des mots trop fréquents\n",
    "    - Construction de critère de séparabilité pour éliminer des mots etc...\n",
    "1. Apprentissage d'un classifieur\n",
    "    - Choix du type de classifieur\n",
    "    - Réglage des paramètres du classifieur (régularisation, etc...)\n",
    "\n",
    "## Exploitation de la chaine de traitement\n",
    "\n",
    "On appelle cette étape la réalisation d'une campagne d'expériences: c'est le point clé que nous voulons traviller en TAL cette année.\n",
    "1. Il est impossible de tester toutes les combinaisons par rapport aux propositions ci-dessus... Il faut donc en éliminer un certain nombre.\n",
    "    - En discutant avec les experts métiers\n",
    "    - En faisant des tests préliminaires\n",
    "1. Après ce premier filtrage, il faut:\n",
    "    - Choisir une évaluation fiable et pas trop lente (validation croisée, leave-one-out, split apprentissage/test simple)\n",
    "    - Lancer des expériences en grand\n",
    "        - = *grid-search*\n",
    "        - parallèliser sur plusieurs machines\n",
    "        - savoir lancer sur un serveur et se déconnecter\n",
    "1. Collecter et analyser les résultats\n",
    "\n",
    "\n",
    "## Inférence\n",
    "\n",
    "L'inférence est ensuite très classique: la chaine de traitement optimale est apte à traiter de nouveaux documents\n",
    "\n",
    "# Etape 1: charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import re\n",
    "import os.path\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57413 57413\n",
      "[\" Quand je dis chers amis, il ne s'agit pas là d'une formule diplomatique, mais de l'expression de ce que je ressens.\\n\", \" D'abord merci de cet exceptionnel accueil que les Congolais, les Brazavillois, nous ont réservé cet après-midi.\\n\", \" C'est toujours très émouvant de venir en Afrique car c'est probablement l'une des rares terres du monde où l'on ait conservé cette convivialité, cette amitié, ce respect de l'autre qui s'expriment avec chaleur, avec spontanéité et qui réchauffent le coeur de ceux qui arrivent et de ceux qui reçoivent.\\n\"]\n",
      "[1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données:\n",
    "def load_pres(fname):\n",
    "    alltxts = []\n",
    "    alllabs = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour régler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        #\n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
    "        if lab.count('M') >0:\n",
    "            alllabs.append(-1)\n",
    "        else: \n",
    "            alllabs.append(1)\n",
    "        alltxts.append(txt)\n",
    "    return alltxts,alllabs\n",
    "\n",
    "fname = \"/Users/etienneperez/Documents/IODAA/TAL/ressources/AFDpresidentutf8/corpus.tache1.learn.utf8\"\n",
    "\n",
    "alltxts,alllabs = load_pres(fname)\n",
    "# alltxts : 1 élément = 1 phrase\n",
    "# alllabs : étiquettes de 1 (90%) et -1 (10%) correspondant aux classes de chaque phrase : Chirac ou Mitterand\n",
    "\n",
    "print(len(alltxts),len(alllabs))\n",
    "print(alltxts[0:3])\n",
    "print(alllabs[0:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation paramétrique du texte\n",
    "\n",
    "Vous devez tester, par exemple, les cas suivants:\n",
    "- transformation en minuscule ou pas\n",
    "- suppression de la ponctuation\n",
    "- transformation des mots entièrement en majuscule en marqueurs spécifiques\n",
    "- suppression des chiffres ou pas\n",
    "- conservation d'une partie du texte seulement (seulement la première ligne = titre, seulement la dernière ligne = résumé, ...)\n",
    "- stemming\n",
    "- ...\n",
    "\n",
    "\n",
    "Vérifier systématiquement sur un exemple ou deux le bon fonctionnement des méthodes sur deux documents (au moins un de chaque classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINITION DES FONCTIONS DE PRE TRAITEMENT\n",
    "\n",
    "# Supprimer la ponctuation et les chiffres de toutes les phrases\n",
    "def suppr_ponct(txt): # prend alltxts en entrée\n",
    "    punc = string.punctuation  \n",
    "    punc += '\\n\\r\\t'\n",
    "\n",
    "    for i in range(len(txt)):\n",
    "        txt[i] = txt[i].translate(str.maketrans(punc, ' ' * len(punc)))  \n",
    "        txt[i] = re.sub('[0-9]+', '', txt[i])\n",
    "\n",
    "# Supprimer les accents et caractères spéciaux\n",
    "def suppr_accents_maj(txt): # prend alltxts en entrée\n",
    "    for i in range(len(txt)):\n",
    "        txt[i] = unicodedata.normalize('NFD',  txt[i]).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "        txt[i] =  txt[i].lower()\n",
    "\n",
    "# Stemming\n",
    "def stemming(txt):\n",
    "    ps = PorterStemmer()\n",
    "    compteur = 0\n",
    "    for sentence in txt:\n",
    "        # print(\"sentence : \",sentence)\n",
    "        words = word_tokenize(sentence,language='french')\n",
    "        # print(\"words : \",words)\n",
    "        sentence_new = ''\n",
    "        for word in words:\n",
    "            word_new = ps.stem(word)\n",
    "            sentence_new += word_new + ' '\n",
    "        txt[compteur] = sentence_new\n",
    "        compteur += 1\n",
    "\n",
    "# Lemmatization\n",
    "\n",
    "\n",
    "# Stopword\n",
    "stop_words = stopwords.words('french')\n",
    "\n",
    "# Supprimmer les mots rares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération du dictionnaire {\"mot\" : nombre_occurence}\n",
    "words = []\n",
    "for i in range(len(alltxts)):\n",
    "    for mot in alltxts[i].split():\n",
    "        words.append(mot)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "dico = Counter(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dico qui associe 1 mot à sa position dans le dictionnaire dico\n",
    "trans = dict(zip(list(dico.keys()), np.arange(len(dico)).tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction du vocabulaire\n",
    "\n",
    "Exploration préliminaire des jeux de données.\n",
    "\n",
    "- Quelle est la taille d'origine du vocabulaire?\n",
    "- Que reste-t-il si on ne garde que les 100 mots les plus fréquents? [word cloud]\n",
    "- Quels sont les 100 mots dont la fréquence documentaire est la plus grande? [word cloud]\n",
    "- Quels sont les 100 mots les plus discriminants au sens de odds ratio? [word cloud]\n",
    "- Quelle est la distribution d'apparition des mots (Zipf)\n",
    "- Quels sont les 100 bigrammes/trigrammes les plus fréquents?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27054\n"
     ]
    }
   ],
   "source": [
    "suppr_ponct(alltxts)\n",
    "suppr_accents_maj(alltxts)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(alltxts)\n",
    "\n",
    "print(len(vectorizer.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('de', 69032), ('la', 43944), ('et', 37281), ('l', 36321), ('a', 35180), ('le', 26220), ('les', 26071), ('des', 22319), ('d', 21332), ('est', 17401), ('en', 16553), ('que', 16292), ('qui', 15635), ('un', 12815), ('une', 12669), ('pour', 11964), ('dans', 11820), ('du', 10761), ('je', 10286), ('il', 10037), ('nous', 9590), ('vous', 9499), ('au', 8122), ('ce', 7844), ('c', 7839), ('plus', 7443), ('qu', 6409), ('pas', 6368), ('sur', 5921), ('notre', 5763), ('par', 5740), ('s', 5506), ('ne', 5275), ('france', 5201), ('nos', 4979), ('avec', 4914), ('cette', 4883), ('ou', 4692), ('se', 4511), ('mais', 4493), ('pays', 4464), ('sont', 4388), ('elle', 4385), ('aussi', 4366), ('aux', 4163), ('n', 4044), ('ont', 3954), ('etre', 3821), ('leur', 3775), ('tout', 3688), ('votre', 3653), ('nom', 3530), ('j', 3512), ('tous', 3457), ('son', 3242), ('y', 3240), ('on', 3077), ('bien', 2945), ('ces', 2930), ('meme', 2909), ('ses', 2838), ('comme', 2811), ('entre', 2687), ('europe', 2609), ('sa', 2592), ('hui', 2582), ('aujourd', 2581), ('monde', 2492), ('doit', 2463), ('faire', 2426), ('francais', 2371), ('ai', 2347), ('ils', 2330), ('si', 2231), ('faut', 2117), ('sans', 2105), ('ete', 2070), ('fait', 1976), ('date', 1951), ('etat', 1932), ('leurs', 1816), ('cela', 1782), ('avez', 1757), ('dire', 1718), ('tres', 1710), ('deux', 1693), ('ensemble', 1672), ('peut', 1650), ('developpement', 1627), ('dont', 1625), ('vos', 1578), ('autres', 1560), ('president', 1538), ('politique', 1537), ('monsieur', 1531), ('encore', 1504), ('toutes', 1498), ('vie', 1473), ('avons', 1451), ('ceux', 1434)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fde57402a60>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkoklEQVR4nO3de3hd1X3m8e/v3KQjyZIsWzK2ZJDB4mJIDLGGQEhJJibFzQ06hdZ5ngRP66lbhmaSaTsZmHSeTmeGSXjShoanhY4bUgy5gEtIYUhI4hrSNAkxEZcANhgLjG35Kt9k2dbtHP3mj7NkjmRZOrIlH0n7/TzPec4+6+y1tVZi9Gqvtfbe5u6IiIjEit0AERGZHBQIIiICKBBERCRQIIiICKBAEBGRIFHsBpyu2bNne2NjY7GbISIypTz//PP73b12uO+mbCA0NjbS0tJS7GaIiEwpZrbtVN9pyEhERAAFgoiIBKMGgpldZGYv5b2OmNnnzKzGzNaZ2ZbwPjOvzh1m1mpmm83s+rzyJWb2SvjuHjOzUF5iZo+E8g1m1jghvRURkVMaNRDcfbO7X+7ulwNLgOPAd4HbgfXu3gSsD58xs0XAcuBSYBlwr5nFw+HuA1YBTeG1LJSvBA65+0LgbuCucemdiIgUbKxDRkuBN919G3ADsCaUrwFuDNs3AA+7e4+7bwVagSvNbC5Q6e7Peu4GSg8OqTNwrEeBpQNnDyIicnaMNRCWA98O23PcfTdAeK8L5fXAjrw6baGsPmwPLR9Ux90zQAcwa+gPN7NVZtZiZi3t7e1jbLqIiIyk4EAwsxTwCeAfR9t1mDIfoXykOoML3Fe7e7O7N9fWDruMVkRETtNYzhB+A3jB3feGz3vDMBDhfV8obwPm59VrAHaF8oZhygfVMbMEUAUcHEPbCvbLtw/ylz/cTLZft/0WEck3lkD4JO8MFwE8AawI2yuAx/PKl4eVQwvITR4/F4aVOs3sqjA/cMuQOgPHugl42ifoQQ0vbT/M3zzTyvHezEQcXkRkyiroSmUzKwM+DPxBXvGXgLVmthLYDtwM4O4bzWwtsAnIALe5ezbUuRV4AEgDT4UXwP3AQ2bWSu7MYPkZ9GlEpancgqeu3iwzSpMT9WNERKacggLB3Y8zZJLX3Q+QW3U03P53AncOU94CXDZMeTchUCZaWTIEQl92lD1FRKIlclcql4UzhOO9CgQRkXyRC4RSBYKIyLAiFwgnhowUCCIig0QvEFK5aRPNIYiIDBa5QEifGDLSslMRkXyRDQQNGYmIDBa5QNCyUxGR4UUuENJaZSQiMqzIBUJJIkbMNGQkIjJU5ALBzEgn4zpDEBEZInKBAJBOJTSHICIyRCQDoSwVp0vLTkVEBolkIGjISETkZNEMhFRcQ0YiIkNEMhByQ0YKBBGRfJENBA0ZiYgMFslAKE1qyEhEZKhIBoKGjEREThbRQEjobqciIkNEMhC0ykhE5GQFBYKZVZvZo2b2upm9ZmZXm1mNma0zsy3hfWbe/neYWauZbTaz6/PKl5jZK+G7e8zMQnmJmT0SyjeYWeO49zRPOhmnL+v0Zfsn8seIiEwphZ4hfBX4gbtfDCwGXgNuB9a7exOwPnzGzBYBy4FLgWXAvWYWD8e5D1gFNIXXslC+Ejjk7guBu4G7zrBfIypL6RbYIiJDjRoIZlYJXAvcD+Duve5+GLgBWBN2WwPcGLZvAB529x533wq0Alea2Vyg0t2fdXcHHhxSZ+BYjwJLB84eJoIekiMicrJCzhDOB9qBfzCzF83sa2ZWDsxx990A4b0u7F8P7Mir3xbK6sP20PJBddw9A3QAs06rRwVIJ/VMBBGRoQoJhATwHuA+d78COEYYHjqF4f6y9xHKR6oz+MBmq8ysxcxa2tvbR271CMp0hiAicpJCAqENaHP3DeHzo+QCYm8YBiK878vbf35e/QZgVyhvGKZ8UB0zSwBVwMGhDXH31e7e7O7NtbW1BTR9eOlUAoCuPi09FREZMGoguPseYIeZXRSKlgKbgCeAFaFsBfB42H4CWB5WDi0gN3n8XBhW6jSzq8L8wC1D6gwc6ybg6TDPMCHK9BhNEZGTJArc7zPAN80sBbwF/C65MFlrZiuB7cDNAO6+0czWkguNDHCbuw/85r0VeABIA0+FF+QmrB8ys1ZyZwbLz7BfI9IcgojIyQoKBHd/CWge5qulp9j/TuDOYcpbgMuGKe8mBMrZMLDKqFvLTkVETojklcoaMhIROVk0AyGZOzFSIIiIvCOSgVCaynVbQ0YiIu+IZCCk4jHiMdMdT0VE8kQyEMyMsqSemiYiki+SgQBQqofkiIgMEtlAKNMzEUREBolsIKQ1ZCQiMkhkA0HPVRYRGSyygaDHaIqIDBbdQEgmNGQkIpInsoGQGzLSdQgiIgMiHQg6QxAReUdkA6E0qTkEEZF8kQ0ErTISERks0oGQ6Xd6M/3FboqIyKQQ2UAoDU9N01mCiEhOZAOhLJV7JoLmEUREciIcCANPTdPSUxERiHAgpPUYTRGRQaIbCGEOQU9NExHJKSgQzOxtM3vFzF4ys5ZQVmNm68xsS3ifmbf/HWbWamabzez6vPIl4TitZnaPmVkoLzGzR0L5BjNrHOd+nqRMZwgiIoOM5Qzh37r75e7eHD7fDqx39yZgffiMmS0ClgOXAsuAe80sHurcB6wCmsJrWShfCRxy94XA3cBdp9+lwmjISERksDMZMroBWBO21wA35pU/7O497r4VaAWuNLO5QKW7P+vuDjw4pM7AsR4Flg6cPUyUd1YZaVJZRAQKDwQHfmRmz5vZqlA2x913A4T3ulBeD+zIq9sWyurD9tDyQXXcPQN0ALOGNsLMVplZi5m1tLe3F9j04aVPXIegC9NERAASBe53jbvvMrM6YJ2ZvT7CvsP9Ze8jlI9UZ3CB+2pgNUBzc/NJ349FWstORUQGKegMwd13hfd9wHeBK4G9YRiI8L4v7N4GzM+r3gDsCuUNw5QPqmNmCaAKODj27hRuYFJZVyqLiOSMGghmVm5mMwa2gV8HXgWeAFaE3VYAj4ftJ4DlYeXQAnKTx8+FYaVOM7sqzA/cMqTOwLFuAp4O8wwTJhmPkYiZrlQWEQkKGTKaA3w3zPEmgG+5+w/M7JfAWjNbCWwHbgZw941mthbYBGSA29x94LfurcADQBp4KrwA7gceMrNWcmcGy8ehb6NK65kIIiInjBoI7v4WsHiY8gPA0lPUuRO4c5jyFuCyYcq7CYFyNukW2CIi74jslcqQW3p6XENGIiJAxAOhNKkzBBGRAZEOhLJUXBemiYgEkQ8ETSqLiOREOhDSGjISETkh2oGQius6BBGRINKBoCEjEZF3RDoQ0smEhoxERIJoB0IqRldflgm+S4aIyJQQ6UAoSyXI9ju9Wd0CW0Qk0oHwzjMRNGwkIhLpQCgvyQVCZ7cuThMRiXQgzK8pA2DbgeNFbomISPFFOhAW1lYA8Gb70SK3RESk+CIdCLUzSphRkqB1nwJBRCTSgWBmXFBXoTMEEREiHggAF9QqEEREQIHAwroK9h7p4Uh3X7GbIiJSVJEPhAtqywF4q/1YkVsiIlJcCoS63EojTSyLSNQVHAhmFjezF83syfC5xszWmdmW8D4zb987zKzVzDab2fV55UvM7JXw3T1mZqG8xMweCeUbzKxxHPs4onNrykjGTfMIIhJ5YzlD+CzwWt7n24H17t4ErA+fMbNFwHLgUmAZcK+ZxUOd+4BVQFN4LQvlK4FD7r4QuBu467R6cxqS8RjnzSrnTZ0hiEjEFRQIZtYAfBT4Wl7xDcCasL0GuDGv/GF373H3rUArcKWZzQUq3f1Zz91e9MEhdQaO9SiwdODs4WxYWFtBq84QRCTiCj1D+Gvg80D+bUHnuPtugPBeF8rrgR15+7WFsvqwPbR8UB13zwAdwKyhjTCzVWbWYmYt7e3tBTZ9dBfUlbP9wHH6dNdTEYmwUQPBzD4G7HP35ws85nB/2fsI5SPVGVzgvtrdm929uba2tsDmjO6C2goy/c62A1ppJCLRVcgZwjXAJ8zsbeBh4ENm9g1gbxgGIrzvC/u3AfPz6jcAu0J5wzDlg+qYWQKoAg6eRn9Oy8ITK40UCCISXaMGgrvf4e4N7t5IbrL4aXf/FPAEsCLstgJ4PGw/ASwPK4cWkJs8fi4MK3Wa2VVhfuCWIXUGjnVT+Bln7TFm5+smdyIiJM6g7peAtWa2EtgO3Azg7hvNbC2wCcgAt7n7wBNobgUeANLAU+EFcD/wkJm1kjszWH4G7RqzipIEc6tKtdJIRCJtTIHg7j8Gfhy2DwBLT7HfncCdw5S3AJcNU95NCJRi0T2NRCTqIn+l8oALast5s/0YZ3GkSkRkUlEgBAvrKjjak+FtPT1NRCJKgRBcs3A2Zak4K77+nJafikgkKRCC82sr+NbvX0Vndx+/dd/PeXVnR7GbJCJyVikQ8lw+v5p//MP3UZKIs3z1L3hx+6FiN0lE5KxRIAyxsK6CR2+9mlkVKX73gV+yZW9nsZskInJWKBCGMbcqzTdWvpdUPMan73+OtkOaaBaR6U+BcArza8p4cOWVHO/NcMv9z9FxXI/YFJHpTYEwgovPqeS+Ty3hrf3H+NGmPcVujojIhFIgjKK5cSZmsOtwd7GbIiIyoRQIoyhJxKmtKGHX4a5iN0VEZEIpEAowrzrNrg4FgohMbwqEAtRXp9mpMwQRmeYUCAWYV13KrsNduvGdiExrCoQCzKtO093XzyEtPRWRaUyBUIB51WkATSyLyLSmQChAfQgEzSOIyHSmQCjAwBnCzkMKBBGZvhQIBZhZlqQ0GdOQkYhMawqEApiZrkUQkWlv1EAws1Ize87MfmVmG83sL0J5jZmtM7Mt4X1mXp07zKzVzDab2fV55UvM7JXw3T1mZqG8xMweCeUbzKxxAvp6RnLXIuj2FSIyfRVyhtADfMjdFwOXA8vM7CrgdmC9uzcB68NnzGwRsBy4FFgG3Gtm8XCs+4BVQFN4LQvlK4FD7r4QuBu468y7Nr7mVaU1ZCQi09qogeA5R8PHZHg5cAOwJpSvAW4M2zcAD7t7j7tvBVqBK81sLlDp7s967gqvB4fUGTjWo8DSgbOHyWJedZr2zh56MtliN0VEZEIUNIdgZnEzewnYB6xz9w3AHHffDRDe68Lu9cCOvOptoaw+bA8tH1TH3TNABzBrmHasMrMWM2tpb28vqIPjZV51KQB7OjRsJCLTU0GB4O5Zd78caCD31/5lI+w+3F/2PkL5SHWGtmO1uze7e3Ntbe0orR5fuhZBRKa7Ma0ycvfDwI/Jjf3vDcNAhPd9Ybc2YH5etQZgVyhvGKZ8UB0zSwBVwMGxtG2ivXO1ss4QRGR6KmSVUa2ZVYftNHAd8DrwBLAi7LYCeDxsPwEsDyuHFpCbPH4uDCt1mtlVYX7gliF1Bo51E/C0T7I7yZ1TlRsy0sSyiExXiQL2mQusCSuFYsBad3/SzJ4F1prZSmA7cDOAu280s7XAJiAD3ObuAzOxtwIPAGngqfACuB94yMxayZ0ZLB+Pzo2n0mSc2XpQjohMY6MGgru/DFwxTPkBYOkp6twJ3DlMeQtw0vyDu3cTAmUyq5+p5yKIyPSlK5XHoD48F0FEZDpSIIxB7uK0bj0oR0SmJQXCGMyrTtPVl+WwHpQjItOQAmEM5ulaBBGZxhQIYzBwcdov3z5Ih84SRGSaUSCMwbk1ZSTjxl/8v00s/p8/4j3/ax0/2rin2M0SERkXhVyHIEFVWZKn/+SDbNp9hG0HjrH6J1tZ29LGr196TrGbJiJyxhQIYzS/poz5NWUAbD94nMde2Elvpp9UQidbIjK16bfYGbi2qZbjvVlatk2q2y6JiJwWBcIZeN/C2SRixr+8cXZvxS0iMhEUCGegoiRBc+NMfvLG/mI3RUTkjCkQztAHLqzjtd1H2HtEt8UWkalNgXCGrr1wNgA/0bCRiExxCoQztGhuJbUzSjSPICJTngLhDJkZ1zbV8tPW/WT7ddM7EZm6FAjj4NoLZ3P4eB8vtx0udlNERE6bAmEc/FpTLWbwrQ3bdWtsEZmyFAjjoKY8xcprFvCPz7fx3777ioaORGRK0q0rxskXPnoJpck4f/NMK53dGe7+nctJxpW3IjJ1KBDGiZnxp9dfxIzSBF986nXOqSzlzz62qNjNEhEp2Kh/wprZfDN7xsxeM7ONZvbZUF5jZuvMbEt4n5lX5w4zazWzzWZ2fV75EjN7JXx3j5lZKC8xs0dC+QYza5yAvp4Vf/CBC7jukjn8YOMezSeIyJRSyJhGBvgTd78EuAq4zcwWAbcD6929CVgfPhO+Ww5cCiwD7jWzeDjWfcAqoCm8loXylcAhd18I3A3cNQ59K5prL5xN26Euth88XuymiIgUbNRAcPfd7v5C2O4EXgPqgRuANWG3NcCNYfsG4GF373H3rUArcKWZzQUq3f1Zz/3p/OCQOgPHehRYOnD2MBW9f2Hu6uV/3aJ7HInI1DGmWc8wlHMFsAGY4+67IRcaQF3YrR7YkVetLZTVh+2h5YPquHsG6ABmjaVtk8mC2eXMqyrlZ60KBBGZOgoOBDOrAL4DfM7dj4y06zBlPkL5SHWGtmGVmbWYWUt7++S9VYSZ8f6m2fz8zQNagioiU0ZBgWBmSXJh8E13fywU7w3DQIT3faG8DZifV70B2BXKG4YpH1THzBJAFXDSU2fcfbW7N7t7c21tbSFNL5prFs6mo6uPV3d2FLspIiIFKWSVkQH3A6+5+1fyvnoCWBG2VwCP55UvDyuHFpCbPH4uDCt1mtlV4Zi3DKkzcKybgKd9ii/RuSbMI/xUw0YiMkUUcoZwDfBp4ENm9lJ4fQT4EvBhM9sCfDh8xt03AmuBTcAPgNvcPRuOdSvwNXITzW8CT4Xy+4FZZtYK/DFhxdJUNruihEvmVvJTTSyLyBQx6oVp7v5Thh/jB1h6ijp3AncOU94CXDZMeTdw82htmWrev3AWa36+ja7eLOlUfPQKIiJFpHsrTKD3N9XSm+3nubdPmg4REZl0FAgT6MrGGlLxGM+8vm/0nUVEikyBMIHSqTjXLarjgZ+/zd3r3qBfS1BFZBLTze0m2Fd++3LSyVf56votbNx1hLt/ZzEzSpPFbpaIyEkUCBOsNBnnL29+N5fVV/K/v/caV3/xaZobZ3LV+bO47pI5LKyrKHYTRUQAsKm63L+5udlbWlqK3YwxeX7bIb7zQhsb3jrAm+3HiMeM37umkc9ddyHlJcpmEZl4Zva8uzcP951+C51FS86byZLzcncJ33ukm6+u38Lf/+tWvvfybr74W+/mAxdO7quvRWR606RykcypLOX//Oa7ePQPr6asJMGqB1vo6OordrNEJMIUCEXW3FjDX928mJ5MP997eXexmyMiEaZAmATe3VBFU10F33mhbfSdRUQmiAJhEjAzblrSwPPbDvFW+9FiN0dEIkqBMEn85hX1xAwee2FnsZsiIhGlQJgk6ipLufbCWh57oU1XNItIUSgQJpHfek8Duzq6efatA8VuiohEkAJhEvnwojnMKE2wtmUHU/WCQRGZunRh2iRSmozzicXz+OaG7azbtJfzZpWzaG4lf/zrF1JfnS5280RkmlMgTDJf+OglXHTODLbuP8a2A8d56tXd/HDjHv77xy7ht5vnk3v6qIjI+FMgTDJlqQS3XN144vOOg8f5/KMv81+/8wr/9OIu3nfBLM6dVUZT3QwWzassXkNFZNpRIExy82vK+OZ/eC/f2LCNv/vxm4MmnD93XROfu+7CIrZORKYTBcIUEIsZt1zdyC1XN9LVm2XHoeP83b+8yV//8xYM47PXNRW7iSIyDSgQpph0Ks6Fc2bw5ZsWA3D3P79BzOAzSxUKInJmRl12amZfN7N9ZvZqXlmNma0zsy3hfWbed3eYWauZbTaz6/PKl5jZK+G7eyzMjppZiZk9Eso3mFnjOPdxWorHjC/ftJh/d0U9f7XuDX77755l3aa9uqhNRE5bIdchPAAsG1J2O7De3ZuA9eEzZrYIWA5cGurca2bxUOc+YBXQFF4Dx1wJHHL3hcDdwF2n25moiceML9+8mD//+CJ2Hu7i9x9s4bqv/Atf/P5r/POmvRw+3lvsJorIFFLQE9PCX+1Puvtl4fNm4IPuvtvM5gI/dveLzOwOAHf/Ytjvh8D/AN4GnnH3i0P5J0P9PxjYx92fNbMEsAeo9VEaNhWfmDaRMtl+nnp1Dw/9Yhsvbj9EX9Yxg19rqmXF1efxwYvqiMe0ZFUk6ibiiWlz3H03QAiFulBeD/wib7+2UNYXtoeWD9TZEY6VMbMOYBawf5iOrCJ3lsG55557mk2fnhLxGB9fPI+PL55Hd1+WX+04zM9a9/NIyw5Wrmnh3JoymhtnUltRwqyKFB999zxd7CYig4z3pPJwf4L6COUj1Tm50H01sBpyZwin08AoKE3Gee/5s3jv+bP4zNImfrhxD99+bjsb3jpI+9EeejP9PPSLbTz5R79GVVmy2M0VkUnidANhr5nNzRsy2hfK24D5efs1ALtCecMw5fl12sKQURVw8DTbJUMk4zE+9u55fOzd8wBwd1q2HeKTq3/Bnz76K1Z/eomufhYR4PRvbvcEsCJsrwAezytfHlYOLSA3efxcGF7qNLOrwuqiW4bUGTjWTcDTo80fyOkzM/5NYw13fOQS1m3ay9//61vFbpKITBKjniGY2beBDwKzzawN+HPgS8BaM1sJbAduBnD3jWa2FtgEZIDb3D0bDnUruRVLaeCp8AK4H3jIzFrJnRksH5eeyYh+75pGWt4+yF0/2MzcqjQfXjSH0mR89IoiMm0VtMpoMtIqozPX2d3HjX/7M95sP0YqEaP5vJksrKvAyJ1JNMxM84nF86irLC12U0VknIy0ykiBEHFdvVl+sfUAP9uyn5+27mfPkW7cod+dzu4M8ZjxgQtr+ffva+TaC2uL3VwROUMKBDktb7Yf5TvPt/HYCzvZ29nNF3/zXSy/Ust9RaaykQJBT0yTU7qgtoLPL7uYH/+XD3JtUy23P/YK3/jFtmI3S0QmiG5uJ6MqTcb5v59ewn/85gv82T+9yp6Obi6eO4N0Mk7djFIuq6/U0lWRaUCBIAUpTca571Pv4TPfepG/eaZ10HcXnzODFe9r5MbL60mntFJJZKrSHIKMibuz83AXXb1ZuvqybNp1hDXPbuO13UdIJ+MsrKtgwexyzptVRmkyTjJupJNxLplbyWX1VVraKlJkmlSWCeXu/PLtQ3z/ld282X6UrfuPsfNwF0P/aSXjxqJ5Vbzn3GquOHcmV8yvZm5VKYm4prJEzhYFgpx12X6nL9tPpt/p7O7j5bYOXth+iBe3HeblnYfp7us/se+MkgRVZUma6ipYPL+axQ3VzK9JU1mapDKdpCQR0xyFyDiZiLudiowoHjPisdzwUEVJgrlVaa6/9BwA+rL9bN7Tya/aDrO/s5fDXb0cPNbL67s7+fEbW046szCDVDxGSSJGXWUpF58zg0vmVnLJ3Bk01c2gvjpNTLf2FjljCgQ565LxGJfVV3FZfdVJ3x3tybBxZwf7Ons40t1HR1cf3b1ZerL99PT1s/NwFy/tOMyTL+8+Uac8FWdedZpEPEYybiRiRioRI5WIk07GqE6nqC5LMqM0gZlhBkZuv0TcKE3Gaaqr4JK5lZSX6D8JiS7965dJpaIkwXvPnzXqfke6+9iyt5PNe46yec8R9h7pIdPvZPr7yWSd3kw/HV197OnI0NF1mEPH++jN9I94TDNYMKuc+TVlzKsuZW5Vmtnh+RGzK1LMrUozp7JUDxqSaUuBIFNSZWmSJefVsOS8moL2d3d6s/0nhqPcOREeR3sybN7TycZdR3ht9xF2Hu5i464O9h89+RGkybgxrzpNdTpJOhWnPJWgKp2kpjxFTUWKGaW5OY/SZJzqdJJ51WnmVZdSltJ/ajL56V+pRIKZUZIYuuQ193lmeYr5NWVct2jOoG97MlkOHuvlwNFe2o/2sOtwF22Hcq+Orj66ejPs7ujm9T2dHDjWM2iifKjSZIxkLEY8bqTiMSpKE1SUJJhVnuJd9VW8q6GaproKEnHDzEjGjdqKEk2my1mlQBA5hZJEnLlVaeZWFfao0eO9GY72ZOjp6w9h0seuw13sPJwLkEw2N6TV09fP0d4Mx3pygfKTLfvJ9p+82q88FWdBbTnnz67g3JoyGmammVedpjQZJx6DeCxGImYkw9xJRWnubOXk4BMpjAJBZJyUpRKnNTTU1Ztl0+4O3mo/dmJIq6svy9b9x3iz/SgvbD/E917ZPWxoDKc0GSOdjJOMx0glYswqT4WhqzS1M0qYWZakuixFeSpBIkzCx2JG3IxYmHQfUJKIUVOeorospbmTCFAgiBRZOhUfdT4kk+1nz5Fudnd005fpHzSBngnXfBzpznCkK6zM6svSF1ZmtR/t4Y29nTyzed+Iw1ojiRlUppOkQsiUJGKUJOK58AlzKRUlCcpLEqQSsVwYxS13FhPPDYFVl6WonVFCbUUJ51SVUlOW0nLhSUaBIDIFJOIxGmaW0TCz7LSP4e4c681y6Fgvh4/30dWXJdPfT7Y/FyruTn9/7lkYA3oy/WEepYfDXbmVWr2Zfnoy/XT3ZenOZOnqzbK/s5ejPRmO9Wboy/TT1++jrupKxo26GaWUl8SJmREPw1+lydykfGVpMqzwKglhlFtOnIjlhsjisRjlqTjnVJVyTpUm7seD/hcUiQgzo6Ik95f8/MIWZ52xbDiT6cs6h471sq+zh/bObvYe6WF3Rzd7Orro7usn605/f24lWE9fLoS27j/G/s4ejvVmR/9B5OZcSpPx3NlLMk4qHiOZCCGTiJNO5c5oLAyNxSx3AeXAZH8iZifCJhkfOLPJ/xwjHsbTBi6WLEvljluSiIeQGlw3PmQIzsh9Htgvdzb1zlBdzHLtKNZiAgWCiEyYgSvWSxKEIBr7Gc7AZH1f1nNnH+GWKJms09nTx94wlHbgaC/dfVl6whnMwL65z1n2dfbR3ddPv/uJpwJmsn4itAaOOXD8QudsJkLyRBi9E0jx2MDFlDE+u7SJjy+eN+4/V4EgIpPa6U7Wn6mBM5ZcUPSfuI7FHZzckNjx3izHezP0ZN4ZehuY4+nL9g8KlVy93NDdwL2+ekMAnQipfqcvfDdwnN6wnc0LsOqy5IT0edIEgpktA75KbnH419z9S0VukohEWCxmlMaitYR3Utx32MziwN8CvwEsAj5pZouK2yoRkWiZFIEAXAm0uvtb7t4LPAzcUOQ2iYhEymQJhHpgR97ntlA2iJmtMrMWM2tpb28/a40TEYmCyRIIw62xOmmK391Xu3uzuzfX1taehWaJiETHZAmENmB+3ucGYFeR2iIiEkmTJRB+CTSZ2QIzSwHLgSeK3CYRkUiZFMtO3T1jZn8E/JDcstOvu/vGIjdLRCRSJkUgALj794HvF7sdIiJRZT70ieZThJm1A9tOs/psYP84NmeqiGK/o9hniGa/o9hnGHu/z3P3YVflTNlAOBNm1uLuzcVux9kWxX5Hsc8QzX5Hsc8wvv2eLJPKIiJSZAoEEREBohsIq4vdgCKJYr+j2GeIZr+j2GcYx35Hcg5BREROFtUzBBERGUKBICIiQAQDwcyWmdlmM2s1s9uL3Z6JYGbzzewZM3vNzDaa2WdDeY2ZrTOzLeF9ZrHbOt7MLG5mL5rZk+FzFPpcbWaPmtnr4f/zq6d7v83sP4d/26+a2bfNrHQ69tnMvm5m+8zs1byyU/bTzO4Iv9s2m9n1Y/15kQqECD2IJwP8ibtfAlwF3Bb6eTuw3t2bgPXh83TzWeC1vM9R6PNXgR+4+8XAYnL9n7b9NrN64D8Bze5+Gbnb3Sxnevb5AWDZkLJh+xn+G18OXBrq3Bt+5xUsUoFARB7E4+673f2FsN1J7hdEPbm+rgm7rQFuLEoDJ4iZNQAfBb6WVzzd+1wJXAvcD+Duve5+mGneb3K33UmbWQIoI3d35GnXZ3f/CXBwSPGp+nkD8LC797j7VqCV3O+8gkUtEAp6EM90YmaNwBXABmCOu++GXGgAdUVs2kT4a+DzQH9e2XTv8/lAO/APYajsa2ZWzjTut7vvBP4S2A7sBjrc/UdM4z4Pcap+nvHvt6gFQkEP4pkuzKwC+A7wOXc/Uuz2TCQz+xiwz92fL3ZbzrIE8B7gPne/AjjG9BgqOaUwZn4DsACYB5Sb2aeK26pJ4Yx/v0UtECLzIB4zS5ILg2+6+2OheK+ZzQ3fzwX2Fat9E+Aa4BNm9ja5ocAPmdk3mN59hty/6TZ33xA+P0ouIKZzv68Dtrp7u7v3AY8B72N69znfqfp5xr/fohYIkXgQj5kZuTHl19z9K3lfPQGsCNsrgMfPdtsmirvf4e4N7t5I7v/Xp939U0zjPgO4+x5gh5ldFIqWApuY3v3eDlxlZmXh3/pScvNk07nP+U7VzyeA5WZWYmYLgCbguTEd2d0j9QI+ArwBvAl8odjtmaA+vp/cqeLLwEvh9RFgFrlVCVvCe02x2zpB/f8g8GTYnvZ9Bi4HWsL/3/8EzJzu/Qb+AngdeBV4CCiZjn0Gvk1unqSP3BnAypH6CXwh/G7bDPzGWH+ebl0hIiJA9IaMRETkFBQIIiICKBBERCRQIIiICKBAEBGRQIEgIiKAAkFERIL/D0okIt1s4+lKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Affichage des 100 mots les plus apparus dans les phrases\n",
    "print(dico.most_common(100))\n",
    "freq = [f for w,f in dico.most_common(100)]\n",
    "\n",
    "plt.plot(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question qui devient de plus en plus intéressante avec les approches modernes:\n",
    "est-il possible d'extraire des tri-grammes de lettres pour représenter nos documents?\n",
    "\n",
    "Quelle performances attendrent? Quels sont les avantages et les inconvénients d'une telle approche?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles de Machine Learning\n",
    "\n",
    "Avant de lancer de grandes expériences, il faut se construire une base de travail solide en étudiant les questions suivantes:\n",
    "\n",
    "- Combien de temps ça prend d'apprendre un classifieur NB/SVM/RegLog sur ces données en fonction de la taille du vocabulaire?\n",
    "- La validation croisée est-elle nécessaire? Est ce qu'on obtient les mêmes résultats avec un simple *split*?\n",
    "- La validation croisée est-elle stable? A partir de combien de fold (travailler avec différentes graines aléatoires et faire des statistiques basiques)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etienneperez/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Séparation train / test\n",
    "X_train, X_test, y_train, y_test = train_test_split(alltxts, alllabs, test_size=0.3, random_state=0)\n",
    "\n",
    "# On ajoute à liste_donnees différents jeux de données issus de différents pré-traitements\n",
    "liste_donnees = []\n",
    "\n",
    "# Données avec prétraitements basique (ponctuation/maj/accent)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "liste_donnees.append([X_train_vec,y_train,X_test_vec,y_test,len(vectorizer.get_feature_names()), \"Prétraitements basiques : \"])\n",
    "\n",
    "# Données sans stop-words (+ pré-traitements basiques)\n",
    "vectorizer = CountVectorizer(stop_words = stop_words)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "liste_donnees.append([X_train_vec,y_train,X_test_vec,y_test,len(vectorizer.get_feature_names()), \"Prétraitements basiques + stopwords : \"])\n",
    "\n",
    "# Données avec stemming (+ pré-traitements basiques + stop words)\n",
    "X_train_1 = X_train.copy()\n",
    "X_test_1 = X_test.copy()\n",
    "stemming(X_train_1)\n",
    "stemming(X_test_1)\n",
    "vectorizer = CountVectorizer(stop_words = stop_words)\n",
    "X_train_vec = vectorizer.fit_transform(X_train_1)\n",
    "X_test_vec = vectorizer.transform(X_test_1)\n",
    "liste_donnees.append([X_train_vec,y_train,X_test_vec,y_test,len(vectorizer.get_feature_names()), \"Prétraitements basiques + stopwords + stemming : \"])\n",
    "\n",
    "# Données sans stop-words (+ pré-traitement basiques)\n",
    "#vectorizer = CountVectorizer(stop_words = stop_words, analyzer = 'word', min_df = 0.000001, max_df = 1)\n",
    "#X = vectorizer.fit_transform(alltxts)\n",
    "#liste_donnees.append([X,alllabs,len(vectorizer.get_feature)])\n",
    "\n",
    "# Données n-gram niveau caractère (+ pré-traitement basiques)\n",
    "#vectorizer = CountVectorizer(stop_words = stop_words, analyzer = 'char', min_df = 0.000001, max_df = 1)\n",
    "#X = vectorizer.fit_transform(alltxts)\n",
    "#liste_donnees.append([X,alllabs,len(vectorizer.get_feature)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etienneperez/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitements basiques : \n",
      "taille vocabulaire :  23703\n",
      "Score f1 linear SVM :  0.9349698109472434\n",
      "Score f1 naive Bayes :  0.9387755102040817\n",
      "Score f1 logistic regression :  0.943955475019415\n",
      "Prétraitements basiques + stopwords : \n",
      "taille vocabulaire :  23591\n",
      "Score f1 linear SVM :  0.9342763157894737\n",
      "Score f1 naive Bayes :  0.9396378269617706\n",
      "Score f1 logistic regression :  0.9433134376512341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etienneperez/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitements basiques + stopwords + stemming : \n",
      "taille vocabulaire :  15736\n",
      "Score f1 linear SVM :  0.9358549936084434\n",
      "Score f1 naive Bayes :  0.9389395275899245\n",
      "Score f1 logistic regression :  0.942621625989979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "scores = [] # Liste où on stocke les scores \n",
    "for liste in liste_donnees:\n",
    "\n",
    "    # Pour chaque classifieur, on optimise ses paramètres en train avec gridSearch puis on calcule score f1 en test.\n",
    "    ## Linear SVM \n",
    "    clf_svm = svm.LinearSVC(random_state=0, tol=1e-5)\n",
    "    clf_svm.fit(liste[0],liste[1])\n",
    "    \n",
    "    ## Naive Bayes\n",
    "    clf_nb = nb.MultinomialNB()\n",
    "    clf_nb.fit(liste[0],liste[1])\n",
    "\n",
    "    ## logistic regression\n",
    "    clf_log = LogisticRegression(max_iter=1000)\n",
    "    clf_log.fit(liste[0],liste[1])\n",
    "    \n",
    "    print(liste[5])\n",
    "    print(\"taille vocabulaire : \",liste[4])\n",
    "    print(\"Score f1 linear SVM : \",f1_score(clf_svm.predict(liste[2]),liste[3]))\n",
    "    print(\"Score f1 naive Bayes : \",f1_score(clf_nb.predict(liste[2]),liste[3]))\n",
    "    print(\"Score f1 logistic regression : \",f1_score(clf_log.predict(liste[2]),liste[3]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première campagne d'expériences\n",
    "\n",
    "Les techniques sur lesquelles nous travaillons étant sujettes au sur-apprentissage: trouver le paramètre de régularisation dans la documentation et optimiser ce paramètre au sens de la métrique qui vous semble la plus appropriée (cf question précédente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equilibrage des données\n",
    "\n",
    "Un problème reconnu comme dur dans la communauté est celui de l'équilibrage des classes (*balance* en anglais). Que faire si les données sont à 80, 90 ou 99% dans une des classes?\n",
    "Le problème est dur mais fréquent; les solutions sont multiples mais on peut isoler 3 grandes familles de solution.\n",
    "\n",
    "1. Ré-équilibrer le jeu de données: supprimer des données dans la classe majoritaire et/ou sur-échantilloner la classe minoritaire.<BR>\n",
    "   $\\Rightarrow$ A vous de jouer pour cette technique\n",
    "1. Changer la formulation de la fonction de coût pour pénaliser plus les erreurs dans la classe minoritaire:\n",
    "soit une fonction $\\Delta$ mesurant les écarts entre $f(x_i)$ et $y_i$ \n",
    "$$C = \\sum_i  \\alpha_i \\Delta(f(x_i),y_i), \\qquad \\alpha_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{si } y_i \\in \\text{classe majoritaire}\\\\\n",
    "B>1 & \\text{si } y_i \\in \\text{classe minoritaire}\\\\\n",
    "\\end{array} \\right.$$\n",
    "<BR>\n",
    "   $\\Rightarrow$ Les SVM et d'autres approches sklearn possèdent des arguments pour régler $B$ ou $1/B$... Ces arguments sont utiles mais pas toujours suffisant.\n",
    "1. Courbe ROC et modification du biais. Une fois la fonction $\\hat y = f(x)$ apprise, il est possible de la *bidouiller* a posteriori: si toutes les prédictions $\\hat y$ sont dans une classe, on va introduire $b$ dans $\\hat y = f(x) + b$ et le faire varier jusqu'à ce qu'un des points change de classe. On peut ensuite aller de plus en plus loin.\n",
    "Le calcul de l'ensemble des scores associés à cette approche mène directement à la courbe ROC.\n",
    "\n",
    "**Note:** certains classifieurs sont intrinsèquement plus résistante au problème d'équilibrage, c'est par exemple le cas des techniques de gradient boosting que vous verrez l'an prochain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
